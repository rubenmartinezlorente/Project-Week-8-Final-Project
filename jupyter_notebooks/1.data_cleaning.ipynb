{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------\n",
    "\n",
    "# 1st STEP: SLICING SUPERSET\n",
    "\n",
    "## Reading two dasets with 227 countries which repeat ciclycally for 5 different attributes:\n",
    "### We have 5 datasets inside of one 'SUPER'dataset*. *Need to split them up in five separately*\n",
    "### total\n",
    "### renewable\n",
    "### fossil fuel\n",
    "---------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity = pd.read_csv('../raw_data/electricity_capacity.csv',sep=',',header=4, quotechar='\"',decimal=',')\n",
    "generation = pd.read_csv('../raw_data/electricity_generation.csv',sep=',',header=4, quotechar='\"',decimal=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each dataset we define the names we want to split it up: their name categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_generation = ['Generation', 'Nuclear', 'Renewables', 'Fossil Fuels', 'Hydroelectric Pumped Storage']\n",
    "categories_capacity = ['Capacity', 'Nuclear', 'Renewables', 'Fossil Fuels', 'Hydroelectric Pumped Storage']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We save the index where the different datasets have to been splitted up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "for i in categories_generation:\n",
    "    indexes.append(generation[generation['Unnamed: 1'] == i].index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing every dataset (from a total of 2: generation and capacity of eletrical energy) and save them in two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definition of slicing function\n",
    "\n",
    "def slicing(df, indexes):\n",
    "    dataframes = []\n",
    "    for i in range(len(indexes) - 1):\n",
    "        dataframes.append(df.iloc[indexes[i]: indexes[i + 1]])\n",
    "    else:\n",
    "        dataframes.append(df.iloc[indexes[i + 1]:])\n",
    "    return dataframes\n",
    "\n",
    "##saving the datases in a list of dataframes\n",
    "\n",
    "generation = slicing(generation,indexes)\n",
    "capacity = slicing (capacity,indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename all dataset (5 datasets from the 2 initial 'SUPER'dataset), makes a total of 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_total= generation[0].reset_index(drop=True)\n",
    "gen_nuclear = generation[1].reset_index(drop=True)\n",
    "gen_renewable = generation[2].reset_index(drop=True) \n",
    "gen_fossil = generation[3].reset_index(drop=True) \n",
    "gen_hidro = generation[4].reset_index(drop=True) \n",
    "\n",
    "cap_total = capacity[0].reset_index(drop=True)\n",
    "cap_nuclear = capacity[1].reset_index(drop=True)\n",
    "cap_renewable = capacity[2].reset_index(drop=True)\n",
    "cap_fossil = capacity[3].reset_index(drop=True)\n",
    "cap_hidro = capacity[4].reset_index(drop=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the other 4 'simple' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumption = pd.read_csv('../raw_data/electricity_consumption.csv',sep=',',header=4, quotechar='\"',decimal=',')\n",
    "exports = pd.read_csv('../raw_data/electricity_exports.csv',sep=',',header=4, quotechar='\"',decimal=',')\n",
    "imports = pd.read_csv('../raw_data/electricity_imports.csv',sep=',',header=4, quotechar='\"',decimal=',')\n",
    "population = pd.read_csv('../raw_data/population.csv',sep=',',header=4, quotechar='\"',decimal=',')\n",
    "GDP = pd.read_csv('../raw_data/GDP.csv',sep=',',header=4, quotechar='\"',decimal=',')\n",
    "C02 = pd.read_csv('../raw_data/C02emissons.csv',sep=',',header=4, quotechar='\"',decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering all useful datasets as function of how many initial rows we need to drop, because there is just the category of attribute. \n",
    "\n",
    "## That information it in the name of the proper dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = [consumption, exports, imports, population, gen_total,cap_total,gen_renewable,cap_renewable,GDP,C02]\n",
    "features_2 = [gen_nuclear, gen_fossil, gen_hidro, cap_nuclear,cap_fossil,cap_hidro]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2nd STEP: CLEANING SUPERSET\n",
    "\n",
    "## Define two functions: *CLEAN1* and *CLEAN2* to clean all datasets on an authomatized way.\n",
    "\n",
    "---------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN1 FUNCTION: *dataset with two first rows to drop*\n",
    "\n",
    "### #1 dropping the empty  and the units columns\n",
    "\n",
    "### #2 dropping the first 2 rows because there are the quantity to analyze and the category\n",
    "\n",
    "### #3 rename the country column\n",
    "\n",
    "### #4 Set'country' index\n",
    "\n",
    "### #5 Replacing '--', '-' for nan. I discover for trial and error.\n",
    "\n",
    "### #6 Drop the missing values.\n",
    "\n",
    "### #7 Convert the data from objetct to number (float or int)\n",
    "\n",
    "### #8  Transpose the matrix to have the country as index and year as columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean1(df):\n",
    "    #1\n",
    "    df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "    df.drop('Unnamed: 2',axis=1,inplace=True)\n",
    "\n",
    "    #2\n",
    "    df.drop([0,1],axis=0,inplace=True)\n",
    "\n",
    "    #3\n",
    "    df=df.transpose()\n",
    "\n",
    "    #4        \n",
    "    header = df.iloc[0]\n",
    "    df =df[1:]\n",
    "    df.rename(columns =header,inplace=True)\n",
    "    df.insert(0,'year', df.index)\n",
    "    df.reset_index(drop =True, inplace=True)\n",
    "\n",
    "    #5\n",
    "    df.replace('--', np.nan, inplace=True)\n",
    "    df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "    #6\n",
    "    df.dropna(axis=1,inplace=True)\n",
    "\n",
    "    #7\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new1 = []\n",
    "for df in features_1:\n",
    "    features_new1.append(clean1(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## CLEAN2 FUNCTION: *dataset with just first row to drop*\n",
    "\n",
    "### #1 dropping the empty  and the units columns\n",
    "\n",
    "### #2 dropping the first 2 rows because there are the quantity to analyze and the category\n",
    "\n",
    "### #3 rename the country column\n",
    "\n",
    "### #4 Set'country' index\n",
    "\n",
    "### #5 Replacing '--', '-' for nan. I discover for trial and error.\n",
    "\n",
    "### #6 Drop the missing values.\n",
    "\n",
    "### #7 Convert the data from objetct to number (float or int)\n",
    "\n",
    "### #8  Transpose the matrix to have the country as index and year as columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2(df):\n",
    "    #1\n",
    "    df.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "\n",
    "    df.drop('Unnamed: 2',axis=1,inplace=True)\n",
    "\n",
    "    #2\n",
    "    df.drop([0],axis=0,inplace=True)\n",
    "\n",
    "    #3\n",
    "    df=df.transpose()\n",
    "\n",
    "    #4        \n",
    "    header = df.iloc[0]\n",
    "    df =df[1:]\n",
    "    df.rename(columns =header,inplace=True)\n",
    "    df.insert(0,'year', df.index)\n",
    "    df.reset_index(drop =True, inplace=True)\n",
    "\n",
    "    #5\n",
    "    df.replace('--', np.nan, inplace=True)\n",
    "    df.replace('-', np.nan, inplace=True)\n",
    "\n",
    "    #6\n",
    "    df.dropna(axis=1,inplace=True)\n",
    "\n",
    "    #7\n",
    "    df = df.apply(pd.to_numeric)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_new2 = []\n",
    "for df in features_2:\n",
    "    features_new2.append(clean2(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------\n",
    "\n",
    "# 3rd Read and clean the ranking datasets\n",
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_consumption_2017 = pd.read_csv('../raw_data/ranking/electricity_net_consumption_2017.csv',sep=',',header=5, quotechar='\"',decimal=',',index_col='Ranking')\n",
    "ranking_renewable_2017 = pd.read_csv('../raw_data/ranking/renewable_electricity_net_generation_2017.csv',sep=',',header=5, quotechar='\"',decimal=',',index_col='Ranking')\n",
    "ranking_norenewable_2017 = pd.read_csv('../raw_data/ranking/fossil_fuels_electricity_net_generation_2017.csv',sep=',',header=5, quotechar='\"',decimal=',',index_col='Ranking')\n",
    "ranking_CO2_emissions_2016 = pd.read_csv('../raw_data/ranking/CO2_emissions_2016.csv',sep=',',header=5, quotechar='\"',decimal=',',index_col='Ranking')\n",
    "rankings=list([ranking_consumption_2017, ranking_renewable_2017, ranking_norenewable_2017,ranking_CO2_emissions_2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking = []\n",
    "for item in rankings:\n",
    "            item.drop('Unnamed: 0',axis=1, inplace=True)\n",
    "            item['Value'] = pd.to_numeric(item['Value'],errors='coerce')\n",
    "            item.dropna(inplace=True)\n",
    "            feature_ranking.append(item)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = ['consumption', 'exports', 'imports', 'population', 'generation_total','capacity_total','generation_renewable','capacity_renewable','GDP','C02']\n",
    "features_2 = ['generation_nuclear', 'generation_fossil', 'generation_hidrodynamic', 'capacity_nuclear','capacity_fossil','capacity_hidro']\n",
    "namesranking = ['ranking_consumption_2017','ranking_renewable_2017', 'ranking_norenewable_2017','ranking_CO2_emissions_2016']\n",
    "\n",
    "\n",
    "saving1 = [features_new1[i].to_csv(f\"../cleaned_data/{j}.csv\",index= False) for (i,j) in zip(range(len(features_new1)),features_1)]\n",
    "saving2 = [features_new2[k].to_csv(f\"../cleaned_data/{l}.csv\",index= False) for (k,l) in zip(range(len(features_new2)),features_2)]\n",
    "saving_rankining = [feature_ranking[m].to_csv(f\"../cleaned_data/ranking/{n}.csv\",index= False) for (m,n) in zip(range(len(feature_ranking)),namesranking)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
